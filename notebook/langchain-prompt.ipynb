{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init AIPROXY env\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'openai' from '/Users/lingoace/Documents/GitHub/llm-101/venv/lib/python3.10/site-packages/openai/__init__.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path\n",
    "\n",
    "# sys.path.insert(1, os.path.join(os.getcwd()  , '..'))\n",
    "\n",
    "from app.init import init_llm\n",
    "\n",
    "init_llm(2)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a custom prompt template\n",
    "docs: https://python.langchain.com/en/latest/modules/prompts/prompt_templates/examples/custom_prompt_template.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import StringPromptTemplate\n",
    "from pydantic import BaseModel, validator\n",
    "import inspect\n",
    "\n",
    "def get_source_code(fn_name):\n",
    "    return inspect.getsource(fn_name)\n",
    "\n",
    "\n",
    "class FunctionExplainerPromptTeamplte(StringPromptTemplate, BaseModel):\n",
    "    \"\"\"A custom promt template that takes in the function name as input, and formats the prompt template to\n",
    "    provide a description of the function.\n",
    "\n",
    "    Args:\n",
    "        StringPromptTemplate (_type_): _description_\n",
    "        BaseModel (_type_): _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    @validator(\"input_variables\")\n",
    "    def validate_input_variables(cls, v):\n",
    "        if len(v) != 1 or 'fn_name' not in v:\n",
    "            raise ValueError('input_variables must be a list of length 1, containing the variable fn_name')\n",
    "        return v\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        source_code = get_source_code(kwargs['fn_name'])\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "            Give the function name and source code, explain what the function does.\n",
    "            Function Name: {kwargs['fn_name'].__name__}\n",
    "            Source Code: \n",
    "            ```\n",
    "            {source_code}\n",
    "            ```\n",
    "            Explanation:\n",
    "        \"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def _prompt_type(self) -> str:\n",
    "        return 'function-explainer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            Give the function name and source code, explain what the function does.\n",
      "            Function Name: req_api\n",
      "            Source Code: \n",
      "            ```\n",
      "            def req_api(url: str, count: int):\n",
      "    return requests.get(url, count=count)    \n",
      "\n",
      "            ```\n",
      "            Explanation:\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def req_api(url: str, count: int):\n",
    "    return requests.get(url, count=count)    \n",
    "\n",
    "fn_explainer = FunctionExplainerPromptTeamplte(input_variables=['fn_name'])\n",
    "\n",
    "prompt = fn_explainer.format(fn_name=req_api)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            This function is called req_api and it takes two parameters: url (of type string) and count (of type int). The function uses the requests library to make an HTTP GET request to the given url parameter with the given count parameter. The function then returns the response from the request.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(max_tokens=100, temperature=0.5)\n",
    "print(llm(prompt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
