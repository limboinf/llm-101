{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Guides\n",
    "\n",
    "docs: https://python.langchain.com/en/latest/modules/memory/how_to_guides.html\n",
    "\n",
    "### Memory Types\n",
    "- ConversationBufferMemory\n",
    "- ConversationBufferWindowMemory\n",
    "- Entity Memory\n",
    "- Conversation Knowledage Graph Memory\n",
    "- ConversationSummaryMemory\n",
    "- ConversationSummaryBufferMemory\n",
    "- ConversationTokenBufferMemory\n",
    "- VectorStore-Backed Memory\n",
    "\n",
    "### 重点\n",
    "\n",
    "这些Memory, 构造参数如果添加`return_messages=True` 则一般与聊天模型一起使用"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationBufferMemory\n",
    "\n",
    "docs: https://python.langchain.com/en/latest/modules/memory/types/buffer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init OpenAI env\n"
     ]
    }
   ],
   "source": [
    "from app.init import init_llm\n",
    "init_llm()\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='hi', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='whats up', additional_kwargs={}, example=False)]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memory = ConversationBufferMemory()\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "memory.save_context({'input': 'hi'}, {'output': 'whats up'})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 你知道三国时期有哪几个国家，它们的国君分别是谁吗？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 是的，我知道三国时期有曹魏，蜀汉，吴国和东吴四个国家，曹魏的国君是曹操，蜀汉的国君是刘备，吴国的国君是孙权，东吴的国君是孙策。'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using this in a chain (setting verbose=True  will see the prompt)\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "chain = ConversationChain(llm = OpenAI(), memory = ConversationBufferMemory(), verbose=True)\n",
    "chain.predict(input='你知道三国时期有哪几个国家，它们的国君分别是谁吗？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 你知道三国时期有哪几个国家，它们的国君分别是谁吗？\n",
      "AI:  是的，我知道三国时期有曹魏，蜀汉，吴国和东吴四个国家，曹魏的国君是曹操，蜀汉的国君是刘备，吴国的国君是孙权，东吴的国君是孙策。\n",
      "Human: 当时哪个国家最强大?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 在三国时期，曹魏是最强大的国家，但东吴也有强大的实力。'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input='当时哪个国家最强大?')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationBufferWindowMemory\n",
    "docs: https://python.langchain.com/en/latest/modules/memory/types/buffer_window.html\n",
    "\n",
    "**相当于滑动窗口**\n",
    "\n",
    ">ConversationBufferWindowMemory 会保留一份对话随时间变化的交互列表。它只使用最后 K 个交互。这对于保持最近交互的滑动窗口很有用，因此缓冲区不会变得太大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: not much you\\nAI: not much\\nHuman: great\\nAI: thanks'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=2) # 最近的2次对话\n",
    "\n",
    "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
    "memory.save_context({\"input\": \"not much you\"}, {\"output\": \"not much\"})\n",
    "memory.save_context({\"input\": \"great\"}, {\"output\": \"thanks\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 二战期间，哪个国家牺牲最多？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 根据历史记载，二战期间，苏联牺牲最多，其次是中国，紧随其后的是日本。苏联在二战期间牺牲了约2700万人，中国牺牲了约1400万人，日本牺牲了约800万人。'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using in a chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "conversation_with_window = ConversationChain(\n",
    "    llm=OpenAI(temperature=0), \n",
    "    # We set a low k=2, to only keep the last 2 interactions in memory\n",
    "    memory=ConversationBufferWindowMemory(k=2), \n",
    "    verbose=True\n",
    ")\n",
    "conversation_with_window.predict(input=\"二战期间，哪个国家牺牲最多？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 二战期间，哪个国家牺牲最多？\n",
      "AI:  根据历史记载，二战期间，苏联牺牲最多，其次是中国，紧随其后的是日本。苏联在二战期间牺牲了约2700万人，中国牺牲了约1400万人，日本牺牲了约800万人。\n",
      "Human: 它们分别做出了什么贡献\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 苏联在二战期间为自由世界作出了巨大贡献，其中包括抗击德国军队，抵抗纳粹的压迫，以及在战争中取得的胜利。中国也发挥了重要作用，其中包括抗击日本军队，抵抗日本的侵略，以及在战争中取得的胜利。日本也发挥了重要作用，其中包括抗击苏联军队，抵抗苏'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_window.predict(input=\"它们分别做出了什么贡献\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 二战期间，哪个国家牺牲最多？\n",
      "AI:  根据历史记载，二战期间，苏联牺牲最多，其次是中国，紧随其后的是日本。苏联在二战期间牺牲了约2700万人，中国牺牲了约1400万人，日本牺牲了约800万人。\n",
      "Human: 它们分别做出了什么贡献\n",
      "AI:  苏联在二战期间为自由世界作出了巨大贡献，其中包括抗击德国军队，抵抗纳粹的压迫，以及在战争中取得的胜利。中国也发挥了重要作用，其中包括抗击日本军队，抵抗日本的侵略，以及在战争中取得的胜利。日本也发挥了重要作用，其中包括抗击苏联军队，抵抗苏\n",
      "Human: 它们之中当时哪个国家最强大?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 根据历史记载，二战期间，苏联是最强大的国家，其次是美国，紧随其后的是中国和日本。苏联在二战期间拥有最大的军队，最先进的武器，以及最强大的经济实力。'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_window.predict(input=\"它们之中当时哪个国家最强大?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 它们分别做出了什么贡献\n",
      "AI:  苏联在二战期间为自由世界作出了巨大贡献，其中包括抗击德国军队，抵抗纳粹的压迫，以及在战争中取得的胜利。中国也发挥了重要作用，其中包括抗击日本军队，抵抗日本的侵略，以及在战争中取得的胜利。日本也发挥了重要作用，其中包括抗击苏联军队，抵抗苏\n",
      "Human: 它们之中当时哪个国家最强大?\n",
      "AI:  根据历史记载，二战期间，苏联是最强大的国家，其次是美国，紧随其后的是中国和日本。苏联在二战期间拥有最大的军队，最先进的武器，以及最强大的经济实力。\n",
      "Human: 它们之中哪些是法西斯\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 根据历史记载，二战期间，德国、日本和意大利是法西斯国家。这三个国家都支持纳粹的政策，并且在战争中支持纳粹的侵略。'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_window.predict(input=\"它们之中哪些是法西斯\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ConversationEntityMemory\n",
    "docs: https://python.langchain.com/en/latest/modules/memory/types/entity_summary_memory.html\n",
    "\n",
    "记住关于特定实体的事情。它提取实体上的信息(使用LLMs)，随着时间的推移构建其关于该实体的知识(也使用LLMs)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Deven & Sam are working on a hackathon project\\nAI:  That sounds like a great project! What kind of project are they working on?',\n",
       " 'entities': {'Sam': 'Sam is working on a hackathon project with Deven.'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "memory = ConversationEntityMemory(llm=llm)\n",
    "\n",
    "_input = {\"input\": \"Deven & Sam are working on a hackathon project\"}\n",
    "memory.load_memory_variables(_input)\n",
    "\n",
    "memory.save_context(\n",
    "    _input,\n",
    "    {\"output\": \" That sounds like a great project! What kind of project are they working on?\"}\n",
    ")\n",
    "\n",
    "memory.load_memory_variables({\"inputs\": \"who is Sam?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
