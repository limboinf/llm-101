{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init AIPROXY env\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'openai' from '/Users/lingoace/Documents/GitHub/llm-101/venv/lib/python3.10/site-packages/openai/__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from app.init import init_llm\n",
    "init_llm(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parital Prompt Templates\n",
    "对于常规的提示模版，需要先准备好input_variables 变量才行。\n",
    "\n",
    "部分提示模版就是可以让某个变量来部分提示模版，然后等待剩余的变量都准备OK。\n",
    "\n",
    "部分提示模版也可以做参数传递，这样就会比较灵活，而非要全部input_variables 都准备OK了，且都在一个位置才行。\n",
    "\n",
    "docs: https://python.langchain.com/en/latest/modules/prompts/prompt_templates/examples/partial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foobar\n",
      "foobar\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 部分字符串\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{foo}{bar}\", \n",
    "    input_variables=['foo', 'bar']\n",
    ")\n",
    "\n",
    "# 场景1: 变量都准备\n",
    "print(prompt.format(foo='foo', bar='bar'))\n",
    "\n",
    "# 场景2: 变量部分准好\n",
    "\n",
    "# 在某个时机，foo值准备好了\n",
    "partial_prompt = prompt.partial(foo='foo')\n",
    "\n",
    "# 在另外一个时机，bar值也准备好了\n",
    "print(partial_prompt.format(bar='bar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a funny joke about the day 2023-06-14 13:16:04\n"
     ]
    }
   ],
   "source": [
    "# 部分函数：通过通用的方式获取变量注入到prompt中\n",
    "# 场景：获取当前日期，不能在提示中对其进行硬编码，并且将其与其他输入变量一起传递有点烦人\n",
    "\n",
    "from datetime import datetime\n",
    "def _get_now():\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Tell me a {topic} joke about the day {date}\",\n",
    "    input_variables=['topic', 'date']\n",
    ")\n",
    "\n",
    "partial_prompt = prompt.partial(date=_get_now)\n",
    "print(partial_prompt.format(topic='funny'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a funny joke about the day 2023-06-14 13:21:42\n"
     ]
    }
   ],
   "source": [
    "# you can also just initialize the prompt with the partial function\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Tell me a {topic} joke about the day {date}\",\n",
    "    input_variables=['topic'],\n",
    "    partial_variables={'date': _get_now}\n",
    ")\n",
    "\n",
    "print(prompt.format(topic='funny'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt composition 提示组合\n",
    "\n",
    "docs: https://python.langchain.com/en/latest/modules/prompts/prompt_templates/examples/prompt_composition.html\n",
    "\n",
    "将多个提示组合一起，当要重复使用部分提示时会很有用。\n",
    "\n",
    "通过 `PipelinePrompt` 来实现，两部分：\n",
    "\n",
    "1. `final_prompt`: 最终提示\n",
    "2. `pipeline_prompts`: 元祖列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "# full template, 由 introduction, example, start 三部分组成\n",
    "full_template = \"\"\"{introduction}\n",
    "\n",
    "{example}\n",
    "\n",
    "{start}\"\"\"\n",
    "full_prompt = PromptTemplate.from_template(full_template)\n",
    "\n",
    "# 1.introduction\n",
    "\n",
    "introduction_template = \"\"\"You are impersonating {person}.\"\"\"\n",
    "introduction_prompt = PromptTemplate.from_template(introduction_template)\n",
    "\n",
    "# 2.example\n",
    "example_template = \"\"\"Here's an example of an interaction: \n",
    "\n",
    "Q: {example_q}\n",
    "A: {example_a}\"\"\"\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "# 3.start\n",
    "start_template = \"\"\"Now, do this for real!\n",
    "\n",
    "Q: {input}\n",
    "A:\"\"\"\n",
    "start_prompt = PromptTemplate.from_template(start_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person', 'example_a', 'input', 'example_q']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_prompts = [\n",
    "    ('introduction', introduction_prompt),\n",
    "    ('example', example_prompt),\n",
    "    ('start', start_prompt)\n",
    "]\n",
    "\n",
    "pipeline_prompt = PipelinePromptTemplate(final_prompt=full_prompt, pipeline_prompts=input_prompts)\n",
    "\n",
    "pipeline_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are impersonating Elon Musk.\n",
      "\n",
      "Here's an example of an interaction: \n",
      "\n",
      "Q: What's your favorite car?\n",
      "A: Telsa\n",
      "\n",
      "Now, do this for real!\n",
      "\n",
      "Q: What's your favorite social media site?\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(pipeline_prompt.format(\n",
    "    person=\"Elon Musk\",\n",
    "    example_q=\"What's your favorite car?\",\n",
    "    example_a=\"Telsa\",\n",
    "    input=\"What's your favorite social media site?\"\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
